{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1><centre>PennTree Bank WSJ Corpus</centre></h1>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "list1 = [['a','b','c'],['d','e','f']]\r\n",
    "list2 = [['x','y','z'],['p','q','r']]\r\n",
    "\r\n",
    "list1+list2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['a', 'b', 'c'], ['d', 'e', 'f'], ['x', 'y', 'z'], ['p', 'q', 'r']]"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from prepareDictionary import PennTreeBankDictionary\r\n",
    "ds = PennTreeBankDictionary()\r\n",
    "word_to_idx, idx_to_word, pos_to_idx, idx_to_pos = ds.vocabulary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "preparing look-up dictionaries\n",
      "preparing train/test/valid datasets\n",
      "done\n",
      "done!\n",
      "Total words in the dictionary: 46349 \n",
      "Total POS tags in the dictionary: 46\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "pos_to_idx.keys()\r\n",
    "pos_to_idx['PADDING']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "list1_conll = ['VBZ', '\"', 'WDT', 'DT', 'VBG', 'MD', 'NN', 'WP$', 'NNS', 'PDT', 'WP', '-X-', 'WRB', 'NNPS', 'PRP', 'JJ', 'SYM', '(', 'PRP$', 'EX', 'VBD', \"''\", 'POS', 'RP', ')', ',', 'VBN', 'CD', 'JJS', 'LS', 'NNP', 'TO', 'VB', 'VBP', ':', 'JJR', 'RB', 'CC', '.', 'RBR', '$', 'FW', 'NN|SYM', 'UH', 'RBS', 'IN', 'PADDING']\r\n",
    "list2_penn = ['.', '``', '$', 'WDT', \"''\", 'NNPS', 'UH', 'FW', 'DT', '-RRB-', 'VBG', '#', 'SYM', 'MD', 'PRP$', 'LS', 'EX', 'PDT', 'JJS', 'RBS', 'JJ', 'NNP', 'VBD', 'WP', 'NN', 'NNS', 'VBZ', 'CC', '-LRB-', 'RBR', 'WRB', 'RP', ',', 'POS', 'IN', 'JJR', 'TO', 'VBN', 'PRP', 'WP$', 'VBP', ':', 'VB', 'RB', 'CD', 'PADD']\r\n",
    "\r\n",
    "print([x for x in list1_conll if x not in list2_penn])\r\n",
    "print([x for x in list2_penn if x not in list1_conll])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['\"', '-X-', '(', ')', 'NN|SYM', 'PADDING']\n",
      "['``', '-RRB-', '#', '-LRB-', 'PADD']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def demo():\r\n",
    "    \"\"\"\r\n",
    "    A demonstration of the probabilistic parsers.  The user is\r\n",
    "    prompted to select which demo to run, and how many parses should\r\n",
    "    be found; and then each parser is run on the same demo, and a\r\n",
    "    summary of the results are displayed.\r\n",
    "    \"\"\"\r\n",
    "    import sys, time\r\n",
    "    from nltk import tokenize\r\n",
    "    from nltk.parse import ViterbiParser\r\n",
    "    from nltk.grammar import toy_pcfg1, toy_pcfg2\r\n",
    "    from functools import reduce\r\n",
    "\r\n",
    "    # Define two demos.  Each demo has a sentence and a grammar.\r\n",
    "    demos = [\r\n",
    "        (\"I saw the man with my telescope\", toy_pcfg1),\r\n",
    "        (\"the boy saw Jack with Bob under the table with a telescope\", toy_pcfg2),\r\n",
    "    ]\r\n",
    "\r\n",
    "    # Ask the user which demo they want to use.\r\n",
    "    print()\r\n",
    "    for i in range(len(demos)):\r\n",
    "        print(\"%3s: %s\" % (i + 1, demos[i][0]))\r\n",
    "        print(\"     %r\" % demos[i][1])\r\n",
    "        print()\r\n",
    "    print(\"Which demo (%d-%d)? \" % (1, len(demos)), end=\" \")\r\n",
    "    try:\r\n",
    "        snum = int(sys.stdin.readline().strip()) - 1\r\n",
    "        sent, grammar = demos[snum]\r\n",
    "    except:\r\n",
    "        sent, grammar = demos[0]\r\n",
    "        print(\"Bad sentence number\")\r\n",
    "        # return\r\n",
    "\r\n",
    "    # Tokenize the sentence.\r\n",
    "    tokens = sent.split()\r\n",
    "\r\n",
    "    parser = ViterbiParser(grammar)\r\n",
    "    all_parses = {}\r\n",
    "\r\n",
    "    print(\"\\nsent: %s\\nparser: %s\\ngrammar: %s\" % (sent, parser, grammar))\r\n",
    "    parser.trace(3)\r\n",
    "    t = time.time()\r\n",
    "    parses = parser.parse_all(tokens)\r\n",
    "    time = time.time() - t\r\n",
    "    average = (\r\n",
    "        reduce(lambda a, b: a + b.prob(), parses, 0) / len(parses) if parses else 0\r\n",
    "    )\r\n",
    "    num_parses = len(parses)\r\n",
    "    for p in parses:\r\n",
    "        all_parses[p.freeze()] = 1\r\n",
    "\r\n",
    "    # Print some summary statistics\r\n",
    "    print()\r\n",
    "    print(\"Time (secs)   # Parses   Average P(parse)\")\r\n",
    "    print(\"-----------------------------------------\")\r\n",
    "    print(\"%11.4f%11d%19.14f\" % (time, num_parses, average))\r\n",
    "    parses = all_parses.keys()\r\n",
    "    if parses:\r\n",
    "        p = reduce(lambda a, b: a + b.prob(), parses, 0) / len(parses)\r\n",
    "    else:\r\n",
    "        p = 0\r\n",
    "    print(\"------------------------------------------\")\r\n",
    "    print(\"%11s%11d%19.14f\" % (\"n/a\", len(parses), p))\r\n",
    "\r\n",
    "    # Ask the user if we should draw the parses.\r\n",
    "    print()\r\n",
    "    print(\"Draw parses (y/n)? \", end=\" \")\r\n",
    "    if sys.stdin.readline().strip().lower().startswith(\"y\"):\r\n",
    "        from nltk.draw.tree import draw_trees\r\n",
    "\r\n",
    "        print(\"  please wait...\")\r\n",
    "        draw_trees(*parses)\r\n",
    "\r\n",
    "    # Ask the user if we should print the parses.\r\n",
    "    print()\r\n",
    "    print(\"Print parses (y/n)? \", end=\" \")\r\n",
    "    if sys.stdin.readline().strip().lower().startswith(\"y\"):\r\n",
    "        for parse in parses:\r\n",
    "            print(parse)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "if __name__ == \"__main__\":\r\n",
    "    demo()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "  1: I saw the man with my telescope\n",
      "     <Grammar with 17 productions>\n",
      "\n",
      "  2: the boy saw Jack with Bob under the table with a telescope\n",
      "     <Grammar with 23 productions>\n",
      "\n",
      "Which demo (1-2)?  Bad sentence number\n",
      "\n",
      "sent: I saw the man with my telescope\n",
      "parser: <ViterbiParser for <Grammar with 17 productions>>\n",
      "grammar: Grammar with 17 productions (start state = S)\n",
      "    S -> NP VP [1.0]\n",
      "    NP -> Det N [0.5]\n",
      "    NP -> NP PP [0.25]\n",
      "    NP -> 'John' [0.1]\n",
      "    NP -> 'I' [0.15]\n",
      "    Det -> 'the' [0.8]\n",
      "    Det -> 'my' [0.2]\n",
      "    N -> 'man' [0.5]\n",
      "    N -> 'telescope' [0.5]\n",
      "    VP -> VP PP [0.1]\n",
      "    VP -> V NP [0.7]\n",
      "    VP -> V [0.2]\n",
      "    V -> 'ate' [0.35]\n",
      "    V -> 'saw' [0.65]\n",
      "    PP -> P NP [1.0]\n",
      "    P -> 'with' [0.61]\n",
      "    P -> 'under' [0.39]\n",
      "Inserting tokens into the most likely constituents table...\n",
      "   Insert: |=......| I\n",
      "   Insert: |.=.....| saw\n",
      "   Insert: |..=....| the\n",
      "   Insert: |...=...| man\n",
      "   Insert: |....=..| with\n",
      "   Insert: |.....=.| my\n",
      "   Insert: |......=| telescope\n",
      "Finding the most likely constituents spanning 1 text elements...\n",
      "   Insert: |=......| NP -> 'I' [0.15]               0.1500000000 \n",
      "   Insert: |.=.....| V -> 'saw' [0.65]              0.6500000000 \n",
      "   Insert: |.=.....| VP -> V [0.2]                  0.1300000000 \n",
      "   Insert: |..=....| Det -> 'the' [0.8]             0.8000000000 \n",
      "   Insert: |...=...| N -> 'man' [0.5]               0.5000000000 \n",
      "   Insert: |....=..| P -> 'with' [0.61]             0.6100000000 \n",
      "   Insert: |.....=.| Det -> 'my' [0.2]              0.2000000000 \n",
      "   Insert: |......=| N -> 'telescope' [0.5]         0.5000000000 \n",
      "Finding the most likely constituents spanning 2 text elements...\n",
      "   Insert: |==.....| S -> NP VP [1.0]               0.0195000000 \n",
      "   Insert: |..==...| NP -> Det N [0.5]              0.2000000000 \n",
      "   Insert: |.....==| NP -> Det N [0.5]              0.0500000000 \n",
      "Finding the most likely constituents spanning 3 text elements...\n",
      "   Insert: |.===...| VP -> V NP [0.7]               0.0910000000 \n",
      "   Insert: |....===| PP -> P NP [1.0]               0.0305000000 \n",
      "Finding the most likely constituents spanning 4 text elements...\n",
      "   Insert: |====...| S -> NP VP [1.0]               0.0136500000 \n",
      "Finding the most likely constituents spanning 5 text elements...\n",
      "   Insert: |..=====| NP -> NP PP [0.25]             0.0015250000 \n",
      "Finding the most likely constituents spanning 6 text elements...\n",
      "   Insert: |.======| VP -> VP PP [0.1]              0.0002775500 \n",
      "   Insert: |.======| VP -> V NP [0.7]               0.0006938750 \n",
      "  Discard: |.======| VP -> VP PP [0.1]              0.0002775500 \n",
      "Finding the most likely constituents spanning 7 text elements...\n",
      "   Insert: |=======| S -> NP VP [1.0]               0.0001040812 \n",
      "\n",
      "Time (secs)   # Parses   Average P(parse)\n",
      "-----------------------------------------\n",
      "     0.0101          1   0.00010408125000\n",
      "------------------------------------------\n",
      "        n/a          1   0.00010408125000\n",
      "\n",
      "Draw parses (y/n)?  \n",
      "Print parses (y/n)?  "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('tf': conda)"
  },
  "interpreter": {
   "hash": "75c4db28bb58e6de10e05be21b6046b5ba21d9aba4af4007d97c2f3325bc0896"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}